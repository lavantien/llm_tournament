# Bots

---

## Llama-3.1-Nemotron-70B-Instruct-HF-IQ2_M

- Path: "mradermacher/Llama-3.3-70B-Instruct-i1-GGUF/Llama-3.3-70B-Instruct.i1-IQ2_M.gguf"
- Size: 24.12
- Param: 70
- Quant: "iq2m"
- GPU Layers: 80
- GPU Layers Used: 21
- Ctx: 131072
- Ctx Used: 32768

---

## Llama-3.3-70B-Instruct.i1-IQ2_M

- Path: "bartowski/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF/Llama-3.1-Nemotron-70B-Instruct-HF-IQ2_M.gguf"
- Size: 24.12
- Param: 70
- Quant: "iq2m"
- GPU Layers: 80
- GPU Layers Used: 21
- Ctx: 131072
- Ctx Used: 32768

---

## Qwen2.5-32B-Instruct-Q5_K_L

- Path: "bartowski/Qwen2.5-32B-Instruct-GGUF/Qwen2.5-32B-Instruct-Q5_K_L.gguf"
- Size: 23.74
- Param: 32
- Quant: "q5kl"
- GPU Layers: 64
- GPU Layers Used: 17
- Ctx: 32768
- Ctx Used: 32768

---

## Mistral-Small-Instruct-2409-Q8_0

- Path: "bartowski/Mistral-Small-Instruct-2409-GGUF/Mistral-Small-Instruct-2409-Q8_0.gguf"
- Size: 23.64
- Param: 22B
- Quant: "q80"
- GPU Layers: 56
- GPU Layers Used: 15
- Ctx: 131072
- Ctx Used: 32768

---

## Mistral-Small-22B-ArliAI-RPMax-v1.1-q8_0

- Path: "ArliAI/Mistral-Small-22B-ArliAI-RPMax-v1.1-GGUF/Mistral-Small-22B-ArliAI-RPMax-v1.1-q8_0.gguf"
- Size: 23.64
- Param: 22
- Quant: "q80"
- GPU Layers: 56
- GPU Layers Used:15
- Ctx: 32768
- Ctx Used: 32768

---

## Codestral-22B-v0.1-Q8_0

- Path: "bartowski/Codestral-22B-v0.1-GGUF/Codestral-22B-v0.1-Q8_0.gguf"
- Size: 23.64
- Param: 22
- Quant: "q80"
- GPU Layers: 56
- GPU Layers Used: 15
- Ctx: 32768
- Ctx Used: 32768

---

## aya-expanse-32b-Q5_K_L (23.56 GB)

- Path: "bartowski/aya-expanse-32b-GGUF/aya-expanse-32b-Q5_K_L.gguf"
- Size: 23.56
- Param: 32
- Quant: "q5kl"
- GPU Layers: 40
- GPU Layers Used: 11
- Ctx: 131072
- Ctx Used: 32768

---

## c4ai-command-r-08-2024-Q5_K_L

- Path: "bartowski/c4ai-command-r-08-2024-GGUF/c4ai-command-r-08-2024-Q5_K_L.gguf"
- Size: 23.56
- Param: 32
- Quant: "q5kl"
- GPU Layers: 40
- GPU Layers Used: 11
- Ctx: 131072
- Ctx Used: 32768

---

## magnum-v4-27b-Q6_K_L

- Path: "bartowski/magnum-v4-27b-GGUF/magnum-v4-27b-Q6_K_L.gguf"
- Size: 22.63
- Param: 27
- Quant: "q6kl"
- GPU Layers: 46
- GPU Layers Used: 13
- Ctx: 8192
- Ctx Used: 8192

---

## Mixtral-8x7B-Instruct-v0.1-exhaustive-LoRA.i1-IQ3_M

- Path: "mradermacher/Mixtral-8x7B-Instruct-v0.1-exhaustive-LoRA-i1-GGUF/Mixtral-8x7B-Instruct-v0.1-exhaustive-LoRA.i1-IQ3_M.gguf"
- Size: 21.48
- Param: 56
- Quant: "iq3m"
- GPU Layers: 32
- GPU Layers Used: 9
- Ctx: 32768
- Ctx Used: 32768

---

## qwen2.5-coder-14b-instruct-q8_0

- Path: "Qwen/Qwen2.5-Coder-14B-Instruct-GGUF/qwen2.5-coder-14b-instruct-q8_0-00001-of-00002.gguf"
- Size: 15.7
- Param: 14
- Quant: "q80"
- GPU Layers: 48
- GPU Layers Used: 19
- Ctx: 131072
- Ctx Used: 32768

---

## Virtuoso-Small-Q8_0

- Path: "arcee-ai/Virtuoso-Small-GGUF/Virtuoso-Small-Q8_0.gguf"
- Size: 15.7
- Param: 14
- Quant: "q80"
- GPU Layers: 48
- GPU Layers Used: 19
- Ctx: 131072
- Ctx Used: 32768

---

## phi-4-Q8_0

- Path: "matteogeniaccio/phi-4/phi-4-Q8_0.gguf"
- Size: 15.58
- Param: 14.7
- Quant: "q80"
- GPU Layers: 40
- GPU Layers Used: 16
- Ctx: 16384
- Ctx Used: 16384

---

## Mistral-Nemo-Instruct-2407-Q8_0

- Path: "lmstudio-community/Mistral-Nemo-Instruct-2407-GGUF/Mistral-Nemo-Instruct-2407-Q8_0.gguf"
- Size: 13.02
- Param: 12
- Quant: "q80"
- GPU Layers: 40
- GPU Layers Used: 20
- Ctx: 1024000
- Ctx Used: 32768

---

## NemoMix-Unleashed-12B-Q8_0

- Path: "bartowski/NemoMix-Unleashed-12B-GGUF/NemoMix-Unleashed-12B-Q8_0.gguf"
- Size: 13.02
- Param: 12
- Quant: "q80"
- GPU Layers: 40
- GPU Layers Used: 20
- Ctx: 1024000
- Ctx Used: 32768

---

## Rocinante-12B-v1.1-Q8_0

- Path: "TheDrummer/Rocinante-12B-v1.1-GGUF/Rocinante-12B-v1.1-Q8_0.gguf"
- Size: 13.02
- Param: 12
- Quant: "q80"
- GPU Layers: 40
- GPU Layers Used: 20
- Ctx: 1024000
- Ctx Used: 32768

---

## Moistral-11B-v3-Q8_0 (11.40 GB)

- Path: "TheDrummer/Moistral-11B-v3-GGUF/Moistral-11B-v3-Q8_0.gguf"
- Size: 11.4
- Param: 11
- Quant: "q80"
- GPU Layers: 48
- GPU Layers Used: 27
- Ctx: 8192
- Ctx Used: 8192

---

## codegeex4-all-9b-Q8_0 (9.99 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Tiger-Gemma-9B-v3-Q8_0 (9.83 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Darkest-muse-v1-Q8_0 (9.83 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## aya-expanse-8b-Q8_0 (8.54 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## c4ai-command-r7b-12-2024-q8_0 (8.54 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## L3-8B-Stheno-v3.2-Q8_0-imat (8.54 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Hermes-3-Llama-3.1-8B-Q8_0 (8.54 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Ministral-8B-Instruct-2410-Q8_0 (8.53 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Nemotron-Mini-4B-Instruct-f16 (8.39 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Qwen2.5-Coder-7B-Instruct-Q8_0 (8.10 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## SeaLLMs-v3-7B-Chat-Q8_0 (8.10 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Llava-v1.5-7B-Q8_0 (7.79 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## falcon-mamba-7b-instruct-Q8_0 (7.77 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## codeqwen-1_5-7b-chat-q8_0 (7.71 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## mathstral-7B-v0.1.Q8_0 (7.70 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## rho-math-7b-v0.1-Q8_0 (7.70 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Phi-3.5-mini-instruct.f16 (7.64 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Ministral-3b-instruct.f16 (6.63 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Hermes-3-Llama-3.2-3B-f16 (6.43 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Llama-Doctor-3.2-3B-Instruct-f16 (6.43 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Qwen2.5-Coder-3B-Instruct-f16 (6.18 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## SmolLM2-1.7B-Instruct-f16 (3.42 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Llama-3.2-1B-Instruct-f16 (2.48 GB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Qwen2.5-Coder-0.5B-Instruct-f16 (994.16 MB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## Qwen2.5-0.5B-Instruct-f16 (994.16 MB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## SmolLM2-360M-Instruct-f16 (725.55 MB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---

## SmolLM2-135M-Instruct-f16 (270.89 MB)

- Path

- Size

- Param

- Quant

- GPU Layers Used

- Ctx

- Ctx Used

---
