### Schema Design Document

This document outlines the schema for the **Local LLM Playground (LLP)** app, designed to manage LLM stats, prompt outputs, and evaluation results. The schema defines the necessary database tables, relationships, and key attributes for storing LLM information, evaluation scores, prompts, and other application data.

#### Database Overview

The app uses **SQLite 3.47** as the database backend, chosen for its lightweight and minimal resource consumption. The database will store LLM model details, prompts, evaluation results, and other essential data, which will be used by the app for benchmarking, displaying results, and managing user interactions.

#### Tables

##### 1. **llms**

Stores information about each LLM model being evaluated.

| Column Name   | Data Type | Description                                                 |
| ------------- | --------- | ----------------------------------------------------------- |
| `id`          | INTEGER   | Primary Key, unique identifier for the LLM model.           |
| `name`        | TEXT      | Name of the LLM (e.g., "qwen2.5-coder-32b").                |
| `description` | TEXT      | Description of the LLM, including version and capabilities. |
| `version`     | TEXT      | Version of the LLM model (e.g., "v1.0").                    |
| `status`      | TEXT      | Current status of the LLM (e.g., "active", "inactive").     |
| `created_at`  | TIMESTAMP | Date and time when the LLM was added to the database.       |
| `updated_at`  | TIMESTAMP | Date and time of the last update to the LLM's record.       |

##### 2. **prompts**

Stores the prompts used for evaluation and other tasks.

| Column Name   | Data Type | Description                                                     |
| ------------- | --------- | --------------------------------------------------------------- |
| `id`          | INTEGER   | Primary Key, unique identifier for the prompt.                  |
| `title`       | TEXT      | Title of the prompt.                                            |
| `description` | TEXT      | A description of the prompt and its intended use.               |
| `type`        | TEXT      | Type of the prompt (e.g., "general", "programming", "writing"). |
| `created_at`  | TIMESTAMP | Date and time when the prompt was added.                        |
| `updated_at`  | TIMESTAMP | Date and time when the prompt was last updated.                 |

##### 3. **llm_outputs**

Stores outputs generated by LLM models in response to the prompts.

| Column Name  | Data Type | Description                                                                   |
| ------------ | --------- | ----------------------------------------------------------------------------- |
| `id`         | INTEGER   | Primary Key, unique identifier for each output.                               |
| `llm_id`     | INTEGER   | Foreign Key referencing `llms(id)`. The LLM model that generated this output. |
| `prompt_id`  | INTEGER   | Foreign Key referencing `prompts(id)`. The prompt used for this output.       |
| `output`     | TEXT      | The text output generated by the LLM model.                                   |
| `score`      | INTEGER   | The score assigned to this output based on the evaluation criteria.           |
| `created_at` | TIMESTAMP | Date and time when the output was generated.                                  |
| `updated_at` | TIMESTAMP | Date and time when the output was last updated.                               |

##### 4. **evaluation_scores**

Stores the detailed evaluation results of each LLM output, including automated and manual scores.

| Column Name             | Data Type | Description                                                               |
| ----------------------- | --------- | ------------------------------------------------------------------------- |
| `id`                    | INTEGER   | Primary Key, unique identifier for the evaluation score.                  |
| `output_id`             | INTEGER   | Foreign Key referencing `llm_outputs(id)`. The output being evaluated.    |
| `instruction_following` | INTEGER   | Score for how well the LLM followed the instructions (out of 300 points). |
| `quality`               | INTEGER   | Score for the quality of the output (out of 200 points).                  |
| `complexity`            | INTEGER   | Score based on the complexity of the task (out of 640 points).            |
| `creativity`            | INTEGER   | Score for creative problem-solving or writing (out of 630 points).        |
| `total_score`           | INTEGER   | Total score for the output, calculated by summing individual scores.      |
| `created_at`            | TIMESTAMP | Date and time when the evaluation was completed.                          |
| `updated_at`            | TIMESTAMP | Date and time when the evaluation score was last updated.                 |

##### 5. **statistics**

Stores aggregated statistics about the LLMs, prompts, and evaluations for generating reports and charts.

| Column Name     | Data Type | Description                                                                           |
| --------------- | --------- | ------------------------------------------------------------------------------------- |
| `id`            | INTEGER   | Primary Key, unique identifier for the statistics.                                    |
| `llm_id`        | INTEGER   | Foreign Key referencing `llms(id)`. The LLM for which statistics are being generated. |
| `prompt_id`     | INTEGER   | Foreign Key referencing `prompts(id)`. The prompt associated with this statistic.     |
| `average_score` | INTEGER   | The average score for the given prompt and LLM.                                       |
| `total_runs`    | INTEGER   | The total number of runs for the given prompt and LLM.                                |
| `max_score`     | INTEGER   | The highest score achieved by the LLM on the given prompt.                            |
| `min_score`     | INTEGER   | The lowest score achieved by the LLM on the given prompt.                             |
| `created_at`    | TIMESTAMP | Date and time when the statistic was generated.                                       |
| `updated_at`    | TIMESTAMP | Date and time when the statistic was last updated.                                    |

#### Relationships

1. **One-to-Many**:
   - Each LLM model can have multiple outputs (`llm_outputs`), but each output belongs to a single LLM.
   - Each prompt can be used in multiple evaluations, but each evaluation is tied to a specific prompt.
2. **Many-to-One**:
   - Multiple evaluation scores can be associated with a single output.
3. **One-to-One**:
   - Each modelâ€™s statistical data is unique, so `statistics` will have a one-to-one relationship with `llms` and `prompts`.

#### Indices

- **LLM Index**: For faster lookup of LLM details by name or ID in `llms`.
- **Prompt Index**: For faster lookup of prompts by title or ID in `prompts`.
- **Output Index**: For efficient querying of LLM outputs related to specific prompts.
- **Evaluation Score Index**: For quick access to evaluation scores by output ID.

#### Data Integrity

- **Foreign Key Constraints**: Foreign keys are enforced to maintain data integrity. When a referenced record in `llms` or `prompts` is deleted, corresponding records in `llm_outputs` and `evaluation_scores` will either be deleted or updated depending on the chosen cascading action.

#### Schema Diagram

To visualize the relationships between these tables, a **UML Class Diagram** or **Entity-Relationship Diagram (ERD)** will be created. This will define how these entities interact within the application and the underlying database structure.

---

This schema design provides a solid foundation for the database backend of the **Local LLM Playground** app, ensuring that it can efficiently manage the LLM models, prompts, evaluation scores, and statistical data required for benchmarking and reporting.
